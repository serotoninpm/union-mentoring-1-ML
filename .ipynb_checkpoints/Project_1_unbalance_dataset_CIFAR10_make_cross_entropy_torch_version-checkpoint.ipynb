{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M3eOnh39bfO"
   },
   "source": [
    "1. torchvision을 사용하여 CIFAR10의 학습용 데이터, 시험용 데이터 불러오기, 정규화\n",
    "2. 합성곱 신경망 정의\n",
    "3. 손실 함수 정의\n",
    "4. 학습용 데이터를 사용하여 신경망 학습\n",
    "5. 시험용 데이터를 사용하여 신경망 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uXuITn8289eq"
   },
   "outputs": [],
   "source": [
    "#결과 inline에 출력\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FEH4NGb6-KeH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import collections\n",
    "from sklearn import datasets\n",
    "from imblearn import under_sampling\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WbDcVbDtYQxy"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.2+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwxpmJonGrsb",
    "outputId": "0fab87ba-52f8-4d2a-88bf-81fec7f02dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers= 8 ,pin_memory= True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=8, pin_memory= True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  62,  63],\n",
       "       [ 43,  46,  45],\n",
       "       [ 50,  48,  43],\n",
       "       [ 68,  54,  42],\n",
       "       [ 98,  73,  52],\n",
       "       [119,  91,  63],\n",
       "       [139, 107,  75],\n",
       "       [145, 110,  80],\n",
       "       [149, 117,  89],\n",
       "       [149, 120,  93],\n",
       "       [131, 103,  77],\n",
       "       [125,  99,  76],\n",
       "       [142, 115,  91],\n",
       "       [144, 112,  86],\n",
       "       [137, 105,  79],\n",
       "       [129,  97,  71],\n",
       "       [137, 106,  79],\n",
       "       [134, 106,  76],\n",
       "       [124,  97,  64],\n",
       "       [139, 113,  78],\n",
       "       [139, 112,  75],\n",
       "       [133, 105,  69],\n",
       "       [136, 105,  74],\n",
       "       [139, 108,  77],\n",
       "       [152, 120,  89],\n",
       "       [163, 131, 100],\n",
       "       [168, 136, 108],\n",
       "       [159, 129, 102],\n",
       "       [158, 130, 104],\n",
       "       [158, 132, 108],\n",
       "       [152, 125, 102],\n",
       "       [148, 124, 103]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % collections.Counter(trainset.targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unbalance_CIFAR10(CIFAR10):\n",
    "     def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "        super(unbalance_CIFAR10, self).__init__(root, transform=transform,\n",
    "                                    target_transform=target_transform)\n",
    "        \n",
    "\n",
    "     \n",
    "        rus = under_sampling.RandomUnderSampler(\n",
    "            sampling_strategy={\n",
    "                0: 500,\n",
    "                1: 5000,\n",
    "                2: 500,\n",
    "                3: 5000,\n",
    "                4: 500,\n",
    "                5: 5000,\n",
    "                6: 500,\n",
    "                7: 5000,\n",
    "                8: 500,\n",
    "                9: 5000\n",
    "                \n",
    "            },\n",
    "            random_state=42\n",
    "        )\n",
    "        self.data, self.targets = rus.fit_resample(np.array(self.data).reshape(50000,32*32*3), np.array(self.targets))\n",
    "#         self.data, self.targets = torch.Tensor(self.data.reshape(-1,32,32,3)).to(dtype=torch.uint8), torch.Tensor(self.targets).to(dtype=torch.uint8)\n",
    "        self.data, self.targets = self.data.reshape(-1,32,32,3), self.targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = unbalance_CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers= 8 ,pin_memory= True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=8, pin_memory= True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape dataset shape Counter({1: 5000, 3: 5000, 5: 5000, 7: 5000, 9: 5000, 0: 500, 2: 500, 4: 500, 6: 500, 8: 500})\n"
     ]
    }
   ],
   "source": [
    "print('reshape dataset shape %s' % collections.Counter(trainset.targets.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27500, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "rgQfhxpXJZ5f",
    "outputId": "859af676-6ece-430a-a4ff-0b0346bd5bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f65e7260518>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane   dog   cat   car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "print(dataiter)\n",
    "images, labels = dataiter.next()\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB7aQV8uJZv6",
    "outputId": "a827f329-4e7f-4478-b1c1-839409b5d2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
       "    (bn1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "          nn.Conv2d(3, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(32, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "          nn.Conv2d(32, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(64, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(1600, 120)\n",
    "        self.bn1 = nn.BatchNorm1d(120)\n",
    "        self.bn2 = nn.BatchNorm1d(84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NmP7RK2FWytM"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_CE(output,labels):\n",
    "    count_output = len(labels)\n",
    "    loss_total = 0.0\n",
    "    for i in range(count_output):\n",
    "        loss = torch.log(sum(torch.exp(output[i]))) - output[i][labels[i]]\n",
    "        loss_total += loss\n",
    "    return loss_total/count_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()  # 시작 시간 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPYggzAfW0Be",
    "outputId": "14b7fb32-dfdf-4530-c83d-f03b72f2b92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.940\n",
      "[2,    10] loss: 1.377\n",
      "[3,    10] loss: 1.162\n",
      "[4,    10] loss: 1.035\n",
      "[5,    10] loss: 0.930\n",
      "[6,    10] loss: 0.852\n",
      "[7,    10] loss: 0.800\n",
      "[8,    10] loss: 0.746\n",
      "[9,    10] loss: 0.703\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(200):   # 데이터셋을 수차례 반복합니다.\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = custom_CE(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYFO6TofWz-0"
   },
   "outputs": [],
   "source": [
    "# PATH = './fashion_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi8HjximWz5-",
    "outputId": "688f3e8e-f55b-4d0d-b51c-d29a5e2c8c53"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "# 이미지를 출력합니다.\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAQ14i67Xzdk"
   },
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.to(device)\n",
    "# net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xW5s_VvOX2Kr"
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EUVmr_-X2IL",
    "outputId": "07dd4599-2c71-46e0-f132-e1f09e678af2"
   },
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fKdJHWbX2DR",
    "outputId": "038c26f6-4ab3-4954-c104-504a9fdd2d05"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSiYXtBCYEJx",
    "outputId": "26710488-3eac-49fe-defb-67c03011007c"
   },
   "outputs": [],
   "source": [
    "# 각 분류(class)에 대한 예측값 계산을 위해 준비\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UorzWjiYEG7"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJSwc78vQi4Iw7xpvGyCs6",
   "include_colab_link": true,
   "name": "Project 0. pytorch tutorial_jaewook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
