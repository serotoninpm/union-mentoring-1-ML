{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M3eOnh39bfO"
   },
   "source": [
    "1. torchvision을 사용하여 CIFAR10의 학습용 데이터, 시험용 데이터 불러오기, 정규화\n",
    "2. 합성곱 신경망 정의\n",
    "3. 손실 함수 정의\n",
    "4. 학습용 데이터를 사용하여 신경망 학습\n",
    "5. 시험용 데이터를 사용하여 신경망 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uXuITn8289eq"
   },
   "outputs": [],
   "source": [
    "#결과 inline에 출력\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FEH4NGb6-KeH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import FashionMNIST\n",
    "# from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import collections\n",
    "from sklearn import datasets\n",
    "from imblearn import under_sampling\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WbDcVbDtYQxy"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwxpmJonGrsb",
    "outputId": "0fab87ba-52f8-4d2a-88bf-81fec7f02dc4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers= 8 ,pin_memory= True)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=8, pin_memory= True)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({9: 6000, 0: 6000, 3: 6000, 2: 6000, 7: 6000, 5: 6000, 1: 6000, 6: 6000, 4: 6000, 8: 6000})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % collections.Counter(trainset.targets.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unbalance_FashionMNIST(FashionMNIST):\n",
    "     def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "        super(unbalance_FashionMNIST, self).__init__(root, transform=transform,\n",
    "                                    target_transform=target_transform)\n",
    "        \n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "     \n",
    "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
    "        rus = under_sampling.RandomUnderSampler(\n",
    "            sampling_strategy={\n",
    "                0: 600,\n",
    "                1: 6000,\n",
    "                2: 600,\n",
    "                3: 6000,\n",
    "                4: 600,\n",
    "                5: 6000,\n",
    "                6: 600,\n",
    "                7: 6000,\n",
    "                8: 600,\n",
    "                9: 6000\n",
    "                \n",
    "            },\n",
    "            random_state=42\n",
    "        )\n",
    "        self.data, self.targets = rus.fit_resample(np.array(self.data).reshape(60000,28*28), np.array(self.targets))\n",
    "        self.data, self.targets = torch.Tensor(self.data.reshape(-1,28,28)).to(dtype=torch.uint8), torch.Tensor(self.targets).to(dtype=torch.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = unbalance_FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers= 8 ,pin_memory= True)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=8, pin_memory= True)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape dataset shape Counter({1: 6000, 3: 6000, 5: 6000, 7: 6000, 9: 6000, 0: 600, 2: 600, 4: 600, 6: 600, 8: 600})\n"
     ]
    }
   ],
   "source": [
    "print('reshape dataset shape %s' % collections.Counter(trainset.targets.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "rgQfhxpXJZ5f",
    "outputId": "859af676-6ece-430a-a4ff-0b0346bd5bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f1c121ad470>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAAD8CAYAAADE1qz4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFj5JREFUeJztnXl0VFW2xn87iQyGAGFOoJtgZEwTQGiG1qYFUWhR2rafyiCgskyzbF/jcskDfLJIlEUD7Vr9sEUFaQFlUECU1mZ4gNCgrSiDZGAQhEAnMoZgmCQE9/vj3irqpqqSqrokOS/kW+uuunffW7vOV+fcc8/d++x9RFW50RBV1QWoCtSQvlFQQ/pGQQ3pyoCIDBKR/SJyUEQmVvbvA0hlPqdFJBr4BrgbyAO+Aoap6p5KKwSVX9M9gYOqekhVi4F3gd9UchkqnXRL4N8+x3m2zAsRSROR7SKyPTY2VkVEk5KSNDExUevXr6/dunXT1NRUFZFTkRaisklLAJnj/lLVuaraQ1V7XLx4kQEDBrBp0ybS0tI4d+4co0aN4vPPPwc4EmkhKpt0HvATn+NWwHdlfWHDhg3ccsst3uNnn32Wp59+2lUhKpv0V0BbEWkjIrWAocDfy/rC7bff7if78ccfXRUixtW3w4SqlojI08A6IBp4S1Vzgl3ftWtXPvvsMz/5kiVLXJWjUkkDqOpqYHUo1545cyagPDs7mw4dOkRcBqNHZEVFRQBs3brVK2vfvj07d+50pddo0rGxsUyfPp1f/vKXAGRmZrJ69Wo6d+7sSm+lN+9wkJ+fz8SJ10aqqampADRp0sSVXqNrGuDbb7/1k50/f96VTqNJN27cmOTkZPbscQ7N+/Xr50qv0aTj4uLYt28fnTp1csj79OnjSq/RpHNzczlw4IBD1qpVK9q0aeNKr9Gk4+LiuP/++x2yvLw8Ro4c6Upvpb5Ph4vExERNS0sLeC4jI2OHqvaIRK/Rj6xmzZrRvXt3VqxYQZs2bcjIyABAJNDLWugwunkDPPjgg7z88ssOmdvWaTTpq1evsnDhQo4cufbqnJ6ezrlz51zpNZp0UVER/fv35+c//7lX1qJFC06fPu1Kr9Gkjx49SkJCgvd42rRpjB07lrVr17pTrKrGboA2bdpUAZ0yZYpimZY0MTFRge2R6jW6pgFq167tJ/vuuzItTOXCaNKpqank5eWxYcMGh3z//v2u9BpN+vz587z33nsMGDDAK5s9ezabN292pddo0ocOHWLBggUsXrzYKxszZgyZmZmu9BpNunv37vTr14+bb77ZK6tTpw7Tpk1zpziEHvQt4CSQ7SNrBKwHDtif8bZcgFeAg0AmcJvPd0bb1x8ARofae3s2397b3iq0914ADColmwhsVNW2wEb7GODXQFt7SwNeBxCRRsAUoBeWP2uKiMSX98NdunQBYPr06Q752bNnQyh2cJRLWlW3AKVtsb8BFtr7C4EHfORvq4UvgIYikgAMBNar6hlVLcRqHaX/yIDo3bs3eXl53uMRI0Zw8uTJUL4aFJHe081V9RiA/dnMlgdz0JXruPPA14FXUFDA8OHDefXVV73nlyxZwuXLlyMstoXr3ZEFc9CV67jzCn0ceHl5edx3332lz/tZU8JFpO/TJ0QkQVWP2c3X096COejygDtLyTeX9yMJCQksXLiQKVOmAHg/d+/eHWGxbYTYiybh7L3/DEy09ycCM+39wcAarJrtDXzp09sfBuLt7TDQKNLee/ny5a5671AILwWOAVewamwM0Bir1z5gfzbyeWTNBr4FsoAePnqewHqUHQQeD6Vw3bp1U0C3bt16XR9ZRtvIkpKS9J577iEmJoZmzZqRkZHBI488wuzZs2nSpEnENjKjR2SFhYW8+eab1K9f3ytbt26dw6EXCYwm/dOf/hSAGTNmeGVnz56lb9++rvQa3bwrygR83a0d13Pr3LlzwN57/fr11ddyIiIOo6AHCxYscKXXaNIXL15k1apVLFq0yCubO3cuTz75pCu9RpM+evQogwcPZt++fV5ZWloaLVsGHLaHDKNJFxcXs2vXLqZOneqVPffcc7Ro0cKVXqNJ+z6fPbjpppsYPXq0K71Gk27SpAnr1693yP70pz/xxBNPuNJrNOni4mLuvvtuhyw6OtrPZx0ujCbtweHDh737V69eZc6cOa70GU06KsoqXunpFr/73e/c6XX17QrG0aNHA8qr9eDktttuCyj/61//6kqv0aQDzQEdN24cubm5rvQaTbpevXpER0c7ZLNmzareU6qioqK4evWqn7y08T9sva6+XcEINsZ+5JFHXOkt14ggIj8B3gZaAD8Cc1V1lu2qeQ/LUpoLPKyqhWLNd5oF3AtcBB5T1Z22rtHAC7bqqaq6kDJQZUYEIAHbEQfEYQWTdQJm4jQDz7D378VpBt6m18zAh+zPeHs/vpzfDmhEOHz4cMUaEVT1mKemVPUcsBfLJVPh/qzGjRsHlF+8eLG8YpeJsO5pEUkCugHbqCB/lq8vq6SkhA8++MBxfurUqUyePDmcYvshZNIiUg94H3hGVYvKujSALGR/lvr4spKSkvjtb3/rmGOyatWqgCakcBASaRG5CYvwYlVdaYtP2M2WMPxZYQWiXblyBbCCVTx45ZVXGDhwYCjFDopQem/BumfPqOozPvI/AwWqOt0OCW6kqv8lIoOBp7E6tF7AK6ra0+7tdwCeseVOoLuqBo5Domp77zuwmmEm8LW93Usl+LMI0nsfOHCgYh14VbklJyfrkSNHVFUrfc5JlSE2NpbWrVt7g9I8+Oijj1zpNZp0ZmYmgwYNokGDBgDk5OSwZMkS/vWvf7nSa/TMfoDmzZt791NSUq6LTqNrGmDhwjKH5xHBeNIVAaNJB/JkZGdn06NHZI9nD4wm3bJlS/Lz82nVqpVX9rOf/Yx27dq50mt0R5aVlUXPnj3Jz893yN1Gyhtd04mJiQ7CvjXuBkaTLm31zMvLY9GiRTz88MOu9BpNOlBE/KOPPsq7777rSq/x9/SwYcMc79PLli3zunsihdE1DdCrVy+v0X/GjBmsWbOGCRMmuFNa1W9SZW0tWrRQQPv06eN4y3rnnXdcvWUZ3bxFxDvzF67NAj548KA7xVVdm2VtgKanp1dJDEeVoUGDBqSnpzumST7//POOKNtIYDTpJk2acPr0aUfH9fnnn9O6dWtXeo0mXatWLTZv3szKlSu9sk2bNrFr1y5XesslLSJ1RORLEdktIjkikmHL24jINhE5ICLv2am2EJHa9vFB+3ySj65Jtny/iJRrx927dy85OTk8+OCDDnm3bt3CpOlEKDV9Geivql2ArsAgEekNzAD+olZsViHWjH/sz0JVvRX4i30dItIJK/9YCpY75zU70WKZOHbsmJ8s0PyycBCKL0tV1ZM35yZ7U6A/sMKWl/ZlecwdK4C7bNv5b4B3VfWyqh7GMgP3LOu327Vr5zfkfOuttxyzjSJBqB6OaBH5GsuLsR7Lpn1WVUvsS3z9Ul6flX3+eywbedi+rBMnTvDiiy86Yi0LCwuDOvZCRUiDE1W9CnQVkYbAB0DHQJd5yh3kXMi+LGAuQPPmzfWPf/yj99ynn37KhQsXQilymQir91bVs1jxVL2xXLCeP83XL+X1WdnnG2CFLYbtyyouLmb48OEcOnQIgDvuuIOBAwfy/PPPh1PsgETKGxU1BRra+3WBrcB9wHJgqC1/A3jK3v8D8Ia9PxRYZu+nALuB2kAbLKd8dHkjMgK4dXA5IguleScAC+2eNsom8bGI7AHeFZGpwC7gb/b1fwPeEZGDWDU81P5zc0RkGbAHKAH+YN82QdGpUye/tFzXBVU9vi6vpidOnHhjjb3btWvHyJEj2bRpk1e2Z88ev5nB4cJo0nXr1iUlJYWcnGupRX/xi1/w0ksvudJrNOmYmBh69uzpSIN76NAh7rzzTld6b8hgNKNr+tixY/Ts2dObhywjI4PDhw/zq1/9ypVeo0knJyfToEEDh8F/6dKl9O/f35Veo0nHxMQwd+5cSkpKvDLPjCM3MJp0VFQU06ZN81pKzp07xwMPPOAdlkYKo62he/fu5f333/cex8XFAfDhhx+60ntD9t5VPtSsihcOo+/p7t27A/7ey0GDQkqGExRGky4oKODEiRMkJSV5ZefPn2fSpEmu9BpNuqioiIyMDEfNXrp0yS8hcrgwmnSzZs147bXXHNkjmzZtyhdffOFKr9Gkv//++4Dyah1gGsjmvW7dOtf+aaMHJ+3bt6dTp06OkAa3E9zB8Jrev38/2dnZfPPNNw55pU20sQ3+u0TkY/u4wn1ZnTt3ZtmyZd7Jcg88YDlRXnjhhbK+Vi7CqelxWOFJHlS4LysrK8vhrPOMub/66qswih0AIQ4HW2GFLPQHPsbyVpwGYuzzfYB19v46oI+9H2NfJ8AkYJKPTu914Q5D1TpZ4cPQ/wH+CyvsECzfVIX4skLBl19+GcnXvAjFP30fcFJVd/iKA1x6XXxZvg68YNMiP/7447ILXQ5CqenbgSEikou1Zl1/rJqvEF+W+gSjNWrUiLy8PB566CEAOnTowIwZMzh1KuKV4IDQ/NOTVLWVqiZhdUSfqOoIYBPwH/Zlo4FV9v7f7WPs85/Y9+DfgaF2794GK6Fqme00MzOTOXPmeKdQqSoTJkygV69e4XD0g5vByQQq2JeVkJBAVFQUQ4YMAWDo0KGA/6tm2KhqQ0EkvbfbYDSjR2Spqal+OUI7duxI27ZtXek1mnRmZiY7duxwyGbOnEkwu1nIqOomXNaWkpKizZo182veW7durb7NOycnh5MnT7Jt2zaH3LM8XKSoMQGbtnnW4KBU83788cerb/MuKSnh+PHjjBs3ziHfvn27K71Gk27VqhWTJ09m1qxZALzxxhsAzJs3z5Veo81FWVlZLF++nKysLADGjh3L+PHjA66AGA6MrmmwXjJ8Tb4jR450PSHW6JoOhNTUVNerEhtf0yNGjPCTVesVV1JSUgIGjcfEuGugRpPOyclh48aN3hGZx0H/ww8/uNJrNGmA0aNHe1dYSUxMBIIncgoVxpM+fvy4t4Y9y7VW63R7HsydO/e66jOadL169QBchySVhtGkExMTWbFihcPLkZmZWb0fWVFRUfzzn/90yOLj4wMuBhiW3lAuEpFcEckSka9FZLstayQi620H3nrP+ldi4RXbUZcpIrf56BltX3/ATrJYJmrXru2XDXbevHmu18sKyYhgG/p7qOppH9lMrBxlnnxk8ao6QUTuBf6Ta/nIZqlqLzsf2XagB9Z78Q6sfGSFwX63So0IWCkym5SS7QcS7P0EYL+9PwcYVvo6YBgwx0fuuC7QFh8fX6XzyBT4XxHZISKev77CEysGW4h32bJlIRY7MEIdxN6uqt+JSDNgvYjsK+Pa6xaMlpycrIEmv5ZeOCxchFTTqvqd/XkSKwKvJ5WQWLF0los333yTvXv3OsIQI0EortpYEYnz7AP3ANk4HXWlHXij7F68N/C93fzXAfeISLzd099jy4KiTp06juMnn3ySjh0DRTyGiRA6sVuwIud2AznAf9vyKkus2LVr1+qbWDEY6f3791dfE7AnjU9sbKxXlp6eXjkdWVWhVq1a1K5d22HyTU9PZ+nSpa70Gk16x44dXL58mWHDhjnk1TrzXDCsW1dmp18ujCfdr18/P5nb+aFGk05MTHRE1ELgNebDhdGkraQZTnz99dd89tlnrvQaTfrUqVNs377dkQOhY8eOnD59uoxvlQ+jSRcXFxMfH+9dTv3o0aOMGjXKtTW0ZiaCaRtBhqEbNmyovsNQsBYmKI1atWq50mk06U6dOhEfH++Q1a9fv3rnIzt//jx9+/Z1xHDExsZy6dIlV3qNJu1ZGc034fGxY8cc4cWRwOiZCAkJCY4pkZ5sksXFxe4UV3UPXdbWuHFjBTQ6OtrRez/33HPVt/cuKCggLS3Nb6Gwl19+2ZVeo0knJiYGdNNWSlStiDQUkRUisk9E9opIn8rwZZU29TZq1AjAdeaqUGt6FrBWVTsAXbCC0iYCG9UKRttoHwP8Gis+oy2QBrwOlsMPmILl3+oJTPH8UcFw6dIlh1v2zJmgy/CEhxCGgvWBw9jjdB95hfuyqMKcCLcAp4D5dqzlPNvoX+G+rBDKFhFCIR2DtdzT66raDbjAtaYcCNdtkbAOHTq4z+UdAKGQzgPyVNUzvX4F1p9Q4b6sWrVqkZaWxpo1awC8A5VPP/00hGIHRyjBaMeBf4uIZ3myu7Biqyrcl5Wbm0tycrI3bY/n8eXWchLqe21XrFkEmcCHWEs0Vpkv6/XXX6/evqy1a9feWBltwMpe8+ijjzpkW7ZscaXTaNJt27Zl9erVjBw50iH3hDVECqNJ//DDDxQWFrJvnzXbQ0Q4ffp0wEVJwkJV37dlbXXr1vXryPbu3ev6nq4xAZu2EeSR1aFDh+rbewe7d0snewkXRpO+cuUKWVlZ3uicuLg4pk2bxvjx413pNZr0wYMHKS4u9s4nW7t2LfPnz3csRhIJjCZdUlLiTbkHMGTIEObPn+9ab03vbdoG6JYtWxy9d0pKiq5cubL69t5dunShb9++DllOTg5dunRxpddo0keOHEFV/TLQuc1zYjTps2fPIiIkJCR4ZY899pjrpR6NJh0ICxYscKwxHwmMJu15XC1atMghj44udx2iMmE06XPnzpGdne1nRPjHP/7hSq/RpOPi4gKujXXx4kVXekOZ2d/ejsfybEUi8kxl+LLy8/NZu3atI+ywqKjI9T0d7mAhGjgOtAZmAhNt+URghr1/L7AGyyraG9hmyxthrafTCMuaeggrliusV8vc3FzNz8+v1MHJXcC3qnoE52JgpRcJe1stfIGVoS4BGAisV9UzagWgrcfKKhkWkpKSaNkyotSEXoRLeijgmWFeIb6sUOBJARIpwkmWWgsYgrVkVJmXBpCF7MsK5MD75JNPHNeUjuIJF+HU9K+Bnap6wj6uEF+W+jjw2rRpw5w5czz3txelp0OHi3BID+Na04ZK8GWVlJQwYMAA7rrrLod88ODBYRTbHyFNqRKRm4G7gd/7iKcDy0RkDHAUeMiWr8bqwQ8CF4HHAVT1jIi8BHhy2r6oqmVOLYiLiyM5OdkhGzt2rOvJczVGBNM2QLOzs/1MwJMnT66+RoTmzZsze/ZsP3m1XhntxIkTvP322wwfPtwri46O5tZbb3Wl12jS8fHxXLhwgWeffRaAMWPG0LdvX9dZqqr8vg137O2zVc97Ohiq9ft0oFfI7Oxs14MTo0n/+OOPfguQPPXUU671Gk26bt263H///eTl5QFWeENqaio7d+50pdfomf2XLl2idu3aFBQUAJYl9NVXX3WfwKmqe+hIeu+CgoLq3XsXFjqz/CxevNh1XJbRzTs6OtovLmvEiBE0bNjQlV6ja7ply5bs3r3bb/xdKVmqqgoicg5rknxpNAFiVbVpJHqNbt5Y0QJ+78wisl2tJTIigtHNu6JQQ9pABMud6SqnptEdWUXB9JquENSQNgEi8hMR2SQiR0XksoicEpGJkbiGg8E40lgrLI0HrmCl2ywEHgP+TBhhjmWiqt+kgrxd+a6ptwprOapThBHm+P/xLaslVixYEtAN+AKor+G5hoPCVNKCNUR+H3gGKCt1e0guYF+YSvoYcB+wWFVXYrl1i8J0DQeFcaTFSk31e+Am4AN7MsBQ4CPCcw0HR1V3WgE6sTuwmudhrGZ9GWtOS9hhjsG2mmHojYIa0jcKakjfKKghfaPg/wCVPBtp4vew5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouser Dress Ankle boot   Bag\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "print(dataiter)\n",
    "images, labels = dataiter.next()\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB7aQV8uJZv6",
    "outputId": "a827f329-4e7f-4478-b1c1-839409b5d2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
       "    (bn1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "          nn.Conv2d(1, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(32, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "          nn.Conv2d(32, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(64, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 120)\n",
    "        self.bn1 = nn.BatchNorm1d(120)\n",
    "        self.bn2 = nn.BatchNorm1d(84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NmP7RK2FWytM"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_CE(output,labels):\n",
    "    count_output = len(labels)\n",
    "    loss_total = 0.0\n",
    "    for i in range(count_output):\n",
    "        loss = torch.log(sum(torch.exp(output[i]))) - output[i][labels[i]]\n",
    "        loss_total += loss\n",
    "    return loss_total/count_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPYggzAfW0Be",
    "outputId": "14b7fb32-dfdf-4530-c83d-f03b72f2b92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.477\n",
      "[2,    10] loss: 0.585\n",
      "[3,    10] loss: 0.381\n",
      "[4,    10] loss: 0.288\n",
      "[5,    10] loss: 0.236\n",
      "[6,    10] loss: 0.199\n",
      "[7,    10] loss: 0.189\n",
      "[8,    10] loss: 0.167\n",
      "[9,    10] loss: 0.151\n",
      "[10,    10] loss: 0.140\n",
      "[11,    10] loss: 0.135\n",
      "[12,    10] loss: 0.130\n",
      "[13,    10] loss: 0.118\n",
      "[14,    10] loss: 0.115\n",
      "[15,    10] loss: 0.104\n",
      "[16,    10] loss: 0.102\n",
      "[17,    10] loss: 0.104\n",
      "[18,    10] loss: 0.096\n",
      "[19,    10] loss: 0.084\n",
      "[20,    10] loss: 0.084\n",
      "[21,    10] loss: 0.082\n",
      "[22,    10] loss: 0.078\n",
      "[23,    10] loss: 0.077\n",
      "[24,    10] loss: 0.067\n",
      "[25,    10] loss: 0.070\n",
      "[26,    10] loss: 0.067\n",
      "[27,    10] loss: 0.067\n",
      "[28,    10] loss: 0.068\n",
      "[29,    10] loss: 0.060\n",
      "[30,    10] loss: 0.060\n",
      "[31,    10] loss: 0.053\n",
      "[32,    10] loss: 0.051\n",
      "[33,    10] loss: 0.052\n",
      "[34,    10] loss: 0.049\n",
      "[35,    10] loss: 0.045\n",
      "[36,    10] loss: 0.046\n",
      "[37,    10] loss: 0.044\n",
      "[38,    10] loss: 0.040\n",
      "[39,    10] loss: 0.046\n",
      "[40,    10] loss: 0.043\n",
      "[41,    10] loss: 0.038\n",
      "[42,    10] loss: 0.035\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(200):   # 데이터셋을 수차례 반복합니다.\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = custom_CE(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYFO6TofWz-0"
   },
   "outputs": [],
   "source": [
    "# PATH = './fashion_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi8HjximWz5-",
    "outputId": "688f3e8e-f55b-4d0d-b51c-d29a5e2c8c53"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "# 이미지를 출력합니다.\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAQ14i67Xzdk"
   },
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.to(device)\n",
    "# net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xW5s_VvOX2Kr"
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs[0:2], 1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EUVmr_-X2IL",
    "outputId": "07dd4599-2c71-46e0-f132-e1f09e678af2"
   },
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fKdJHWbX2DR",
    "outputId": "038c26f6-4ab3-4954-c104-504a9fdd2d05"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSiYXtBCYEJx",
    "outputId": "26710488-3eac-49fe-defb-67c03011007c"
   },
   "outputs": [],
   "source": [
    "# 각 분류(class)에 대한 예측값 계산을 위해 준비\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UorzWjiYEG7"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJSwc78vQi4Iw7xpvGyCs6",
   "include_colab_link": true,
   "name": "Project 0. pytorch tutorial_jaewook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
