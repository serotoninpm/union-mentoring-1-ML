{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uXuITn8289eq"
   },
   "outputs": [],
   "source": [
    "#결과 inline에 출력\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FEH4NGb6-KeH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WbDcVbDtYQxy"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwxpmJonGrsb",
    "outputId": "0fab87ba-52f8-4d2a-88bf-81fec7f02dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers= 14 ,pin_memory= True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=14, pin_memory= True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "rgQfhxpXJZ5f",
    "outputId": "859af676-6ece-430a-a4ff-0b0346bd5bc7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  deer   car  bird plane   car  deer truck  frog   dog   cat plane   cat  ship  deer   cat  deer   dog   car  frog   cat truck plane  deer   car  bird plane  frog horse truck  bird   dog  ship   dog horse   cat  bird  ship truck  bird horse   cat  ship  bird   car truck truck   cat   car  deer  frog truck   dog horse truck   dog  frog   dog  ship  ship  deer  ship truck  bird  frog   car  bird   cat horse  bird plane  bird truck   car   cat  ship truck  frog   dog truck   dog   dog plane   dog  ship horse   car   car plane  deer  bird plane truck  bird  bird   cat  frog   car   dog horse  bird  bird   dog   car   dog  deer  ship truck  ship  frog  frog   cat horse   cat   cat  ship  frog   cat  ship  ship  ship horse  bird horse  frog  deer truck  deer   cat  frog  bird  frog plane  ship  frog   dog   dog   car truck  bird  frog   dog  ship  frog horse  bird plane  bird  frog  bird  bird plane   cat horse  frog  bird   cat truck truck   cat truck   car   car   dog   car plane  bird  ship  ship plane plane   cat  ship  ship   dog  deer truck   cat   car plane   dog plane plane  ship horse truck  ship   dog  ship  bird truck   car  ship  deer plane  deer   dog   dog  deer plane  bird  ship  ship  bird  frog   car  frog   cat plane truck  frog truck  bird  deer truck horse plane  deer   car  ship   car plane   car plane  frog  bird   dog  bird   cat plane   car plane truck   car  frog  ship horse   cat truck plane  deer  frog  deer   car truck   dog truck  deer truck plane   car   car truck  deer   car  deer   cat  ship   dog   cat  ship truck plane  deer  ship   dog  frog   cat  bird plane  deer  deer  ship  bird   car horse  bird   car  bird   car truck  deer truck   cat   dog   cat  deer  bird  bird truck truck horse   dog truck truck  bird  deer   car horse horse horse   dog   dog plane  bird  ship horse truck  bird   car   car   dog truck   car  deer  bird   dog   cat   cat  frog   car  deer  frog   cat horse   cat horse  bird truck plane truck truck plane horse   dog horse   dog  ship truck   dog  frog  bird plane   cat  bird truck   car horse   car  deer truck   dog   dog plane  deer  deer   dog  ship  bird horse   car   dog  frog  deer   dog  ship  deer horse  bird  ship plane   car  deer   dog horse   dog  ship  ship   cat  bird plane   car horse  ship  ship  deer  bird   cat  ship  ship horse   cat  ship horse   car  bird   dog  bird  bird   cat  deer  bird   cat   car horse plane truck   dog  ship   dog truck  bird   car  deer  frog   car  frog truck   dog horse  frog   dog  bird plane   cat truck   car truck plane horse  frog truck  bird  bird plane  bird truck  deer plane   car  frog  deer horse  frog  frog   car   car   cat  bird plane plane  frog   car  ship plane truck  deer   cat horse plane   car horse  ship plane   cat   car   dog  deer  frog   cat   cat horse  frog   dog  ship truck truck   cat  deer  frog truck   car  bird   car  bird truck  bird horse   cat horse plane   car  frog   car  deer  bird   dog   cat   dog horse  bird  frog horse  bird  ship  bird   dog horse  deer   cat plane   dog  ship truck   car horse plane plane  ship  frog horse  ship   cat  ship plane plane  ship truck  bird   car  frog   dog horse  bird   dog   cat   cat   dog   cat  deer   dog   car  frog  ship  ship   cat truck  deer truck plane  deer  bird  frog   car   dog  frog truck   dog truck   car horse  deer  bird   dog plane truck horse truck horse  frog  ship  ship plane plane horse  frog   cat  frog   car   dog   cat  deer plane truck  ship  ship   dog  frog  deer  bird  frog   car   cat   dog   cat plane  deer  frog  ship   cat  frog  frog  frog   car plane truck  ship  ship  bird  frog horse  bird plane plane  bird truck   cat   car   car   cat  deer  frog   cat  deer  frog  ship truck plane  deer horse   car  bird  ship  deer plane  frog   dog plane  frog truck  bird horse  bird  bird plane   car   car  ship   cat   dog  ship  bird plane horse  frog  frog   cat  bird  bird plane truck   cat  ship truck   cat  deer  bird   cat plane  deer truck   cat  bird horse truck   cat  ship  deer  ship  deer truck  bird  bird plane  frog plane  ship   dog  ship   cat  ship  ship   dog plane  deer  bird  bird  bird horse truck truck truck  ship truck  ship   cat   dog   cat  frog  bird  deer   cat   cat horse  bird   dog truck   cat  deer   cat horse   cat horse   cat plane horse  ship   cat   dog  frog plane  ship truck   car   car  bird  deer horse  deer horse   cat plane  bird  bird  bird  bird   dog   dog  bird  bird   cat horse plane  ship horse   dog horse  bird truck plane plane   car  ship   car   dog   dog horse plane horse plane  deer  frog  ship truck   cat   car  bird plane plane   dog   cat plane  ship horse truck   dog  frog truck   dog   dog horse horse  bird  bird  deer   car horse  bird  bird   cat   car   dog   cat  bird horse   cat horse   car  ship   cat   dog   car horse   cat   car  ship   dog  ship horse horse horse  frog truck plane   car horse  bird  frog  deer  frog   car  bird   dog   cat   car truck horse horse   cat truck   cat   cat   car horse plane   car   car truck truck  frog horse   dog plane plane   car   dog horse   dog horse   dog plane truck   car   car  deer   car  deer   cat  bird   dog  deer  ship   cat truck  frog plane  deer  ship  bird   cat  bird  deer truck   car horse  ship   dog plane   car  frog  frog  bird  frog  frog horse   dog  frog   car   dog  deer   dog  deer  bird  frog plane horse  frog  frog plane   car   cat  deer   car  ship  frog horse   car  frog plane truck truck  deer  bird horse plane   cat  frog  bird   dog horse   dog plane   car plane   dog truck  bird   car plane plane  deer  bird truck  bird plane   car  ship plane horse  ship horse   car   car  deer horse   car plane  ship   cat  ship  bird  ship   car  bird horse  bird  ship   car horse   car  deer  bird  bird truck  frog  bird   cat   cat truck   car horse truck   dog  frog plane  frog   cat  frog   cat  frog   cat horse  bird  deer   cat   car  ship  deer   cat truck  ship  deer  ship  bird plane truck plane truck   cat   dog   car  bird  deer horse horse  deer  deer horse   car   cat  ship horse  deer  bird\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB7aQV8uJZv6",
    "outputId": "a827f329-4e7f-4478-b1c1-839409b5d2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
       "    (bn1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "          nn.Conv2d(3, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(32, 32, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "          nn.Conv2d(32, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(64, 64, 3),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(1600, 120)\n",
    "        self.bn1 = nn.BatchNorm1d(120)\n",
    "        self.bn2 = nn.BatchNorm1d(84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NmP7RK2FWytM"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPYggzAfW0Be",
    "outputId": "14b7fb32-dfdf-4530-c83d-f03b72f2b92a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 2.066\n",
      "[1,    20] loss: 1.745\n",
      "[1,    30] loss: 1.575\n",
      "[1,    40] loss: 1.471\n",
      "[2,    10] loss: 1.328\n",
      "[2,    20] loss: 1.293\n",
      "[2,    30] loss: 1.237\n",
      "[2,    40] loss: 1.206\n",
      "[3,    10] loss: 1.083\n",
      "[3,    20] loss: 1.056\n",
      "[3,    30] loss: 1.024\n",
      "[3,    40] loss: 1.018\n",
      "[4,    10] loss: 0.939\n",
      "[4,    20] loss: 0.900\n",
      "[4,    30] loss: 0.883\n",
      "[4,    40] loss: 0.880\n",
      "[5,    10] loss: 0.828\n",
      "[5,    20] loss: 0.819\n",
      "[5,    30] loss: 0.809\n",
      "[5,    40] loss: 0.792\n",
      "[6,    10] loss: 0.750\n",
      "[6,    20] loss: 0.725\n",
      "[6,    30] loss: 0.739\n",
      "[6,    40] loss: 0.729\n",
      "[7,    10] loss: 0.691\n",
      "[7,    20] loss: 0.691\n",
      "[7,    30] loss: 0.661\n",
      "[7,    40] loss: 0.667\n",
      "[8,    10] loss: 0.624\n",
      "[8,    20] loss: 0.634\n",
      "[8,    30] loss: 0.612\n",
      "[8,    40] loss: 0.654\n",
      "[9,    10] loss: 0.583\n",
      "[9,    20] loss: 0.587\n",
      "[9,    30] loss: 0.597\n",
      "[9,    40] loss: 0.596\n",
      "[10,    10] loss: 0.546\n",
      "[10,    20] loss: 0.558\n",
      "[10,    30] loss: 0.567\n",
      "[10,    40] loss: 0.544\n",
      "[11,    10] loss: 0.519\n",
      "[11,    20] loss: 0.503\n",
      "[11,    30] loss: 0.506\n",
      "[11,    40] loss: 0.527\n",
      "[12,    10] loss: 0.477\n",
      "[12,    20] loss: 0.495\n",
      "[12,    30] loss: 0.480\n",
      "[12,    40] loss: 0.499\n",
      "[13,    10] loss: 0.453\n",
      "[13,    20] loss: 0.461\n",
      "[13,    30] loss: 0.456\n",
      "[13,    40] loss: 0.462\n",
      "[14,    10] loss: 0.423\n",
      "[14,    20] loss: 0.441\n",
      "[14,    30] loss: 0.426\n",
      "[14,    40] loss: 0.448\n",
      "[15,    10] loss: 0.403\n",
      "[15,    20] loss: 0.400\n",
      "[15,    30] loss: 0.418\n",
      "[15,    40] loss: 0.421\n",
      "[16,    10] loss: 0.383\n",
      "[16,    20] loss: 0.382\n",
      "[16,    30] loss: 0.397\n",
      "[16,    40] loss: 0.403\n",
      "[17,    10] loss: 0.347\n",
      "[17,    20] loss: 0.366\n",
      "[17,    30] loss: 0.371\n",
      "[17,    40] loss: 0.383\n",
      "[18,    10] loss: 0.344\n",
      "[18,    20] loss: 0.352\n",
      "[18,    30] loss: 0.351\n",
      "[18,    40] loss: 0.357\n",
      "[19,    10] loss: 0.322\n",
      "[19,    20] loss: 0.336\n",
      "[19,    30] loss: 0.339\n",
      "[19,    40] loss: 0.341\n",
      "[20,    10] loss: 0.297\n",
      "[20,    20] loss: 0.324\n",
      "[20,    30] loss: 0.337\n",
      "[20,    40] loss: 0.338\n",
      "[21,    10] loss: 0.296\n",
      "[21,    20] loss: 0.301\n",
      "[21,    30] loss: 0.315\n",
      "[21,    40] loss: 0.320\n",
      "[22,    10] loss: 0.269\n",
      "[22,    20] loss: 0.286\n",
      "[22,    30] loss: 0.295\n",
      "[22,    40] loss: 0.301\n",
      "[23,    10] loss: 0.268\n",
      "[23,    20] loss: 0.280\n",
      "[23,    30] loss: 0.285\n",
      "[23,    40] loss: 0.297\n",
      "[24,    10] loss: 0.260\n",
      "[24,    20] loss: 0.263\n",
      "[24,    30] loss: 0.256\n",
      "[24,    40] loss: 0.273\n",
      "[25,    10] loss: 0.246\n",
      "[25,    20] loss: 0.243\n",
      "[25,    30] loss: 0.269\n",
      "[25,    40] loss: 0.265\n",
      "[26,    10] loss: 0.239\n",
      "[26,    20] loss: 0.247\n",
      "[26,    30] loss: 0.252\n",
      "[26,    40] loss: 0.258\n",
      "[27,    10] loss: 0.228\n",
      "[27,    20] loss: 0.237\n",
      "[27,    30] loss: 0.241\n",
      "[27,    40] loss: 0.253\n",
      "[28,    10] loss: 0.211\n",
      "[28,    20] loss: 0.230\n",
      "[28,    30] loss: 0.220\n",
      "[28,    40] loss: 0.243\n",
      "[29,    10] loss: 0.216\n",
      "[29,    20] loss: 0.214\n",
      "[29,    30] loss: 0.228\n",
      "[29,    40] loss: 0.228\n",
      "[30,    10] loss: 0.201\n",
      "[30,    20] loss: 0.204\n",
      "[30,    30] loss: 0.216\n",
      "[30,    40] loss: 0.223\n",
      "[31,    10] loss: 0.205\n",
      "[31,    20] loss: 0.208\n",
      "[31,    30] loss: 0.220\n",
      "[31,    40] loss: 0.229\n",
      "[32,    10] loss: 0.193\n",
      "[32,    20] loss: 0.197\n",
      "[32,    30] loss: 0.213\n",
      "[32,    40] loss: 0.206\n",
      "[33,    10] loss: 0.194\n",
      "[33,    20] loss: 0.197\n",
      "[33,    30] loss: 0.210\n",
      "[33,    40] loss: 0.209\n",
      "[34,    10] loss: 0.190\n",
      "[34,    20] loss: 0.180\n",
      "[34,    30] loss: 0.192\n",
      "[34,    40] loss: 0.196\n",
      "[35,    10] loss: 0.176\n",
      "[35,    20] loss: 0.188\n",
      "[35,    30] loss: 0.185\n",
      "[35,    40] loss: 0.192\n",
      "[36,    10] loss: 0.175\n",
      "[36,    20] loss: 0.181\n",
      "[36,    30] loss: 0.175\n",
      "[36,    40] loss: 0.188\n",
      "[37,    10] loss: 0.165\n",
      "[37,    20] loss: 0.172\n",
      "[37,    30] loss: 0.187\n",
      "[37,    40] loss: 0.190\n",
      "[38,    10] loss: 0.163\n",
      "[38,    20] loss: 0.166\n",
      "[38,    30] loss: 0.188\n",
      "[38,    40] loss: 0.190\n",
      "[39,    10] loss: 0.171\n",
      "[39,    20] loss: 0.177\n",
      "[39,    30] loss: 0.175\n",
      "[39,    40] loss: 0.182\n",
      "[40,    10] loss: 0.157\n",
      "[40,    20] loss: 0.158\n",
      "[40,    30] loss: 0.161\n",
      "[40,    40] loss: 0.175\n",
      "[41,    10] loss: 0.161\n",
      "[41,    20] loss: 0.157\n",
      "[41,    30] loss: 0.164\n",
      "[41,    40] loss: 0.170\n",
      "[42,    10] loss: 0.154\n",
      "[42,    20] loss: 0.156\n",
      "[42,    30] loss: 0.163\n",
      "[42,    40] loss: 0.158\n",
      "[43,    10] loss: 0.142\n",
      "[43,    20] loss: 0.152\n",
      "[43,    30] loss: 0.150\n",
      "[43,    40] loss: 0.169\n",
      "[44,    10] loss: 0.136\n",
      "[44,    20] loss: 0.150\n",
      "[44,    30] loss: 0.152\n",
      "[44,    40] loss: 0.161\n",
      "[45,    10] loss: 0.145\n",
      "[45,    20] loss: 0.143\n",
      "[45,    30] loss: 0.147\n",
      "[45,    40] loss: 0.163\n",
      "[46,    10] loss: 0.139\n",
      "[46,    20] loss: 0.143\n",
      "[46,    30] loss: 0.139\n",
      "[46,    40] loss: 0.169\n",
      "[47,    10] loss: 0.135\n",
      "[47,    20] loss: 0.140\n",
      "[47,    30] loss: 0.156\n",
      "[47,    40] loss: 0.159\n",
      "[48,    10] loss: 0.137\n",
      "[48,    20] loss: 0.148\n",
      "[48,    30] loss: 0.146\n",
      "[48,    40] loss: 0.146\n",
      "[49,    10] loss: 0.130\n",
      "[49,    20] loss: 0.141\n",
      "[49,    30] loss: 0.146\n",
      "[49,    40] loss: 0.144\n",
      "[50,    10] loss: 0.136\n",
      "[50,    20] loss: 0.141\n",
      "[50,    30] loss: 0.138\n",
      "[50,    40] loss: 0.147\n",
      "[51,    10] loss: 0.130\n",
      "[51,    20] loss: 0.134\n",
      "[51,    30] loss: 0.137\n",
      "[51,    40] loss: 0.144\n",
      "[52,    10] loss: 0.131\n",
      "[52,    20] loss: 0.129\n",
      "[52,    30] loss: 0.125\n",
      "[52,    40] loss: 0.137\n",
      "[53,    10] loss: 0.127\n",
      "[53,    20] loss: 0.128\n",
      "[53,    30] loss: 0.134\n",
      "[53,    40] loss: 0.145\n",
      "[54,    10] loss: 0.120\n",
      "[54,    20] loss: 0.131\n",
      "[54,    30] loss: 0.130\n",
      "[54,    40] loss: 0.142\n",
      "[55,    10] loss: 0.121\n",
      "[55,    20] loss: 0.119\n",
      "[55,    30] loss: 0.123\n",
      "[55,    40] loss: 0.134\n",
      "[56,    10] loss: 0.123\n",
      "[56,    20] loss: 0.128\n",
      "[56,    30] loss: 0.117\n",
      "[56,    40] loss: 0.139\n",
      "[57,    10] loss: 0.114\n",
      "[57,    20] loss: 0.120\n",
      "[57,    30] loss: 0.123\n",
      "[57,    40] loss: 0.129\n",
      "[58,    10] loss: 0.112\n",
      "[58,    20] loss: 0.115\n",
      "[58,    30] loss: 0.121\n",
      "[58,    40] loss: 0.130\n",
      "[59,    10] loss: 0.112\n",
      "[59,    20] loss: 0.125\n",
      "[59,    30] loss: 0.125\n",
      "[59,    40] loss: 0.122\n",
      "[60,    10] loss: 0.109\n",
      "[60,    20] loss: 0.116\n",
      "[60,    30] loss: 0.119\n",
      "[60,    40] loss: 0.125\n",
      "[61,    10] loss: 0.113\n",
      "[61,    20] loss: 0.121\n",
      "[61,    30] loss: 0.131\n",
      "[61,    40] loss: 0.129\n",
      "[62,    10] loss: 0.115\n",
      "[62,    20] loss: 0.118\n",
      "[62,    30] loss: 0.123\n",
      "[62,    40] loss: 0.118\n",
      "[63,    10] loss: 0.113\n",
      "[63,    20] loss: 0.116\n",
      "[63,    30] loss: 0.112\n",
      "[63,    40] loss: 0.130\n",
      "[64,    10] loss: 0.117\n",
      "[64,    20] loss: 0.115\n",
      "[64,    30] loss: 0.120\n",
      "[64,    40] loss: 0.117\n",
      "[65,    10] loss: 0.114\n",
      "[65,    20] loss: 0.112\n",
      "[65,    30] loss: 0.113\n",
      "[65,    40] loss: 0.124\n",
      "[66,    10] loss: 0.108\n",
      "[66,    20] loss: 0.111\n",
      "[66,    30] loss: 0.114\n",
      "[66,    40] loss: 0.116\n",
      "[67,    10] loss: 0.103\n",
      "[67,    20] loss: 0.109\n",
      "[67,    30] loss: 0.106\n",
      "[67,    40] loss: 0.117\n",
      "[68,    10] loss: 0.105\n",
      "[68,    20] loss: 0.107\n",
      "[68,    30] loss: 0.101\n",
      "[68,    40] loss: 0.110\n",
      "[69,    10] loss: 0.112\n",
      "[69,    20] loss: 0.107\n",
      "[69,    30] loss: 0.112\n",
      "[69,    40] loss: 0.119\n",
      "[70,    10] loss: 0.102\n",
      "[70,    20] loss: 0.102\n",
      "[70,    30] loss: 0.105\n",
      "[70,    40] loss: 0.110\n",
      "[71,    10] loss: 0.094\n",
      "[71,    20] loss: 0.107\n",
      "[71,    30] loss: 0.095\n",
      "[71,    40] loss: 0.112\n",
      "[72,    10] loss: 0.110\n",
      "[72,    20] loss: 0.108\n",
      "[72,    30] loss: 0.101\n",
      "[72,    40] loss: 0.110\n",
      "[73,    10] loss: 0.101\n",
      "[73,    20] loss: 0.090\n",
      "[73,    30] loss: 0.106\n",
      "[73,    40] loss: 0.102\n",
      "[74,    10] loss: 0.097\n",
      "[74,    20] loss: 0.104\n",
      "[74,    30] loss: 0.103\n",
      "[74,    40] loss: 0.098\n",
      "[75,    10] loss: 0.093\n",
      "[75,    20] loss: 0.107\n",
      "[75,    30] loss: 0.098\n",
      "[75,    40] loss: 0.102\n",
      "[76,    10] loss: 0.096\n",
      "[76,    20] loss: 0.100\n",
      "[76,    30] loss: 0.099\n",
      "[76,    40] loss: 0.101\n",
      "[77,    10] loss: 0.096\n",
      "[77,    20] loss: 0.098\n",
      "[77,    30] loss: 0.104\n",
      "[77,    40] loss: 0.112\n",
      "[78,    10] loss: 0.089\n",
      "[78,    20] loss: 0.090\n",
      "[78,    30] loss: 0.097\n",
      "[78,    40] loss: 0.104\n",
      "[79,    10] loss: 0.097\n",
      "[79,    20] loss: 0.103\n",
      "[79,    30] loss: 0.107\n",
      "[79,    40] loss: 0.105\n",
      "[80,    10] loss: 0.101\n",
      "[80,    20] loss: 0.098\n",
      "[80,    30] loss: 0.104\n",
      "[80,    40] loss: 0.103\n",
      "[81,    10] loss: 0.096\n",
      "[81,    20] loss: 0.096\n",
      "[81,    30] loss: 0.104\n",
      "[81,    40] loss: 0.095\n",
      "[82,    10] loss: 0.094\n",
      "[82,    20] loss: 0.099\n",
      "[82,    30] loss: 0.098\n",
      "[82,    40] loss: 0.106\n",
      "[83,    10] loss: 0.093\n",
      "[83,    20] loss: 0.098\n",
      "[83,    30] loss: 0.096\n",
      "[83,    40] loss: 0.098\n",
      "[84,    10] loss: 0.099\n",
      "[84,    20] loss: 0.091\n",
      "[84,    30] loss: 0.089\n",
      "[84,    40] loss: 0.099\n",
      "[85,    10] loss: 0.088\n",
      "[85,    20] loss: 0.096\n",
      "[85,    30] loss: 0.092\n",
      "[85,    40] loss: 0.098\n",
      "[86,    10] loss: 0.094\n",
      "[86,    20] loss: 0.095\n",
      "[86,    30] loss: 0.092\n",
      "[86,    40] loss: 0.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87,    10] loss: 0.091\n",
      "[87,    20] loss: 0.094\n",
      "[87,    30] loss: 0.090\n",
      "[87,    40] loss: 0.095\n",
      "[88,    10] loss: 0.086\n",
      "[88,    20] loss: 0.097\n",
      "[88,    30] loss: 0.092\n",
      "[88,    40] loss: 0.087\n",
      "[89,    10] loss: 0.083\n",
      "[89,    20] loss: 0.093\n",
      "[89,    30] loss: 0.096\n",
      "[89,    40] loss: 0.100\n",
      "[90,    10] loss: 0.097\n",
      "[90,    20] loss: 0.096\n",
      "[90,    30] loss: 0.094\n",
      "[90,    40] loss: 0.093\n",
      "[91,    10] loss: 0.090\n",
      "[91,    20] loss: 0.090\n",
      "[91,    30] loss: 0.092\n",
      "[91,    40] loss: 0.096\n",
      "[92,    10] loss: 0.091\n",
      "[92,    20] loss: 0.089\n",
      "[92,    30] loss: 0.088\n",
      "[92,    40] loss: 0.094\n",
      "[93,    10] loss: 0.086\n",
      "[93,    20] loss: 0.087\n",
      "[93,    30] loss: 0.089\n",
      "[93,    40] loss: 0.107\n",
      "[94,    10] loss: 0.086\n",
      "[94,    20] loss: 0.091\n",
      "[94,    30] loss: 0.087\n",
      "[94,    40] loss: 0.080\n",
      "[95,    10] loss: 0.085\n",
      "[95,    20] loss: 0.077\n",
      "[95,    30] loss: 0.083\n",
      "[95,    40] loss: 0.093\n",
      "[96,    10] loss: 0.076\n",
      "[96,    20] loss: 0.081\n",
      "[96,    30] loss: 0.083\n",
      "[96,    40] loss: 0.096\n",
      "[97,    10] loss: 0.087\n",
      "[97,    20] loss: 0.092\n",
      "[97,    30] loss: 0.093\n",
      "[97,    40] loss: 0.097\n",
      "[98,    10] loss: 0.090\n",
      "[98,    20] loss: 0.086\n",
      "[98,    30] loss: 0.081\n",
      "[98,    40] loss: 0.095\n",
      "[99,    10] loss: 0.077\n",
      "[99,    20] loss: 0.083\n",
      "[99,    30] loss: 0.085\n",
      "[99,    40] loss: 0.093\n",
      "[100,    10] loss: 0.089\n",
      "[100,    20] loss: 0.082\n",
      "[100,    30] loss: 0.083\n",
      "[100,    40] loss: 0.091\n",
      "[101,    10] loss: 0.089\n",
      "[101,    20] loss: 0.083\n",
      "[101,    30] loss: 0.084\n",
      "[101,    40] loss: 0.092\n",
      "[102,    10] loss: 0.078\n",
      "[102,    20] loss: 0.075\n",
      "[102,    30] loss: 0.085\n",
      "[102,    40] loss: 0.098\n",
      "[103,    10] loss: 0.081\n",
      "[103,    20] loss: 0.081\n",
      "[103,    30] loss: 0.081\n",
      "[103,    40] loss: 0.092\n",
      "[104,    10] loss: 0.074\n",
      "[104,    20] loss: 0.082\n",
      "[104,    30] loss: 0.081\n",
      "[104,    40] loss: 0.078\n",
      "[105,    10] loss: 0.074\n",
      "[105,    20] loss: 0.085\n",
      "[105,    30] loss: 0.079\n",
      "[105,    40] loss: 0.085\n",
      "[106,    10] loss: 0.081\n",
      "[106,    20] loss: 0.078\n",
      "[106,    30] loss: 0.079\n",
      "[106,    40] loss: 0.086\n",
      "[107,    10] loss: 0.077\n",
      "[107,    20] loss: 0.079\n",
      "[107,    30] loss: 0.078\n",
      "[107,    40] loss: 0.078\n",
      "[108,    10] loss: 0.075\n",
      "[108,    20] loss: 0.081\n",
      "[108,    30] loss: 0.084\n",
      "[108,    40] loss: 0.085\n",
      "[109,    10] loss: 0.073\n",
      "[109,    20] loss: 0.078\n",
      "[109,    30] loss: 0.079\n",
      "[109,    40] loss: 0.090\n",
      "[110,    10] loss: 0.079\n",
      "[110,    20] loss: 0.080\n",
      "[110,    30] loss: 0.078\n",
      "[110,    40] loss: 0.077\n",
      "[111,    10] loss: 0.076\n",
      "[111,    20] loss: 0.078\n",
      "[111,    30] loss: 0.073\n",
      "[111,    40] loss: 0.083\n",
      "[112,    10] loss: 0.083\n",
      "[112,    20] loss: 0.087\n",
      "[112,    30] loss: 0.084\n",
      "[112,    40] loss: 0.090\n",
      "[113,    10] loss: 0.086\n",
      "[113,    20] loss: 0.079\n",
      "[113,    30] loss: 0.077\n",
      "[113,    40] loss: 0.085\n",
      "[114,    10] loss: 0.078\n",
      "[114,    20] loss: 0.076\n",
      "[114,    30] loss: 0.081\n",
      "[114,    40] loss: 0.086\n",
      "[115,    10] loss: 0.080\n",
      "[115,    20] loss: 0.073\n",
      "[115,    30] loss: 0.075\n",
      "[115,    40] loss: 0.083\n",
      "[116,    10] loss: 0.082\n",
      "[116,    20] loss: 0.077\n",
      "[116,    30] loss: 0.080\n",
      "[116,    40] loss: 0.080\n",
      "[117,    10] loss: 0.087\n",
      "[117,    20] loss: 0.073\n",
      "[117,    30] loss: 0.086\n",
      "[117,    40] loss: 0.081\n",
      "[118,    10] loss: 0.070\n",
      "[118,    20] loss: 0.076\n",
      "[118,    30] loss: 0.078\n",
      "[118,    40] loss: 0.081\n",
      "[119,    10] loss: 0.074\n",
      "[119,    20] loss: 0.078\n",
      "[119,    30] loss: 0.076\n",
      "[119,    40] loss: 0.080\n",
      "[120,    10] loss: 0.078\n",
      "[120,    20] loss: 0.076\n",
      "[120,    30] loss: 0.080\n",
      "[120,    40] loss: 0.075\n",
      "[121,    10] loss: 0.073\n",
      "[121,    20] loss: 0.075\n",
      "[121,    30] loss: 0.079\n",
      "[121,    40] loss: 0.079\n",
      "[122,    10] loss: 0.065\n",
      "[122,    20] loss: 0.067\n",
      "[122,    30] loss: 0.075\n",
      "[122,    40] loss: 0.077\n",
      "[123,    10] loss: 0.078\n",
      "[123,    20] loss: 0.079\n",
      "[123,    30] loss: 0.074\n",
      "[123,    40] loss: 0.077\n",
      "[124,    10] loss: 0.075\n",
      "[124,    20] loss: 0.079\n",
      "[124,    30] loss: 0.078\n",
      "[124,    40] loss: 0.082\n",
      "[125,    10] loss: 0.074\n",
      "[125,    20] loss: 0.069\n",
      "[125,    30] loss: 0.079\n",
      "[125,    40] loss: 0.071\n",
      "[126,    10] loss: 0.067\n",
      "[126,    20] loss: 0.080\n",
      "[126,    30] loss: 0.086\n",
      "[126,    40] loss: 0.072\n",
      "[127,    10] loss: 0.074\n",
      "[127,    20] loss: 0.076\n",
      "[127,    30] loss: 0.080\n",
      "[127,    40] loss: 0.073\n",
      "[128,    10] loss: 0.076\n",
      "[128,    20] loss: 0.074\n",
      "[128,    30] loss: 0.078\n",
      "[128,    40] loss: 0.071\n",
      "[129,    10] loss: 0.072\n",
      "[129,    20] loss: 0.077\n",
      "[129,    30] loss: 0.073\n",
      "[129,    40] loss: 0.074\n",
      "[130,    10] loss: 0.076\n",
      "[130,    20] loss: 0.068\n",
      "[130,    30] loss: 0.069\n",
      "[130,    40] loss: 0.073\n",
      "[131,    10] loss: 0.070\n",
      "[131,    20] loss: 0.068\n",
      "[131,    30] loss: 0.074\n",
      "[131,    40] loss: 0.071\n",
      "[132,    10] loss: 0.061\n",
      "[132,    20] loss: 0.062\n",
      "[132,    30] loss: 0.066\n",
      "[132,    40] loss: 0.075\n",
      "[133,    10] loss: 0.063\n",
      "[133,    20] loss: 0.072\n",
      "[133,    30] loss: 0.071\n",
      "[133,    40] loss: 0.076\n",
      "[134,    10] loss: 0.071\n",
      "[134,    20] loss: 0.072\n",
      "[134,    30] loss: 0.075\n",
      "[134,    40] loss: 0.081\n",
      "[135,    10] loss: 0.069\n",
      "[135,    20] loss: 0.066\n",
      "[135,    30] loss: 0.067\n",
      "[135,    40] loss: 0.074\n",
      "[136,    10] loss: 0.067\n",
      "[136,    20] loss: 0.066\n",
      "[136,    30] loss: 0.067\n",
      "[136,    40] loss: 0.074\n",
      "[137,    10] loss: 0.072\n",
      "[137,    20] loss: 0.070\n",
      "[137,    30] loss: 0.068\n",
      "[137,    40] loss: 0.076\n",
      "[138,    10] loss: 0.069\n",
      "[138,    20] loss: 0.069\n",
      "[138,    30] loss: 0.073\n",
      "[138,    40] loss: 0.073\n",
      "[139,    10] loss: 0.069\n",
      "[139,    20] loss: 0.073\n",
      "[139,    30] loss: 0.068\n",
      "[139,    40] loss: 0.072\n",
      "[140,    10] loss: 0.068\n",
      "[140,    20] loss: 0.071\n",
      "[140,    30] loss: 0.075\n",
      "[140,    40] loss: 0.071\n",
      "[141,    10] loss: 0.068\n",
      "[141,    20] loss: 0.072\n",
      "[141,    30] loss: 0.073\n",
      "[141,    40] loss: 0.074\n",
      "[142,    10] loss: 0.066\n",
      "[142,    20] loss: 0.071\n",
      "[142,    30] loss: 0.077\n",
      "[142,    40] loss: 0.068\n",
      "[143,    10] loss: 0.070\n",
      "[143,    20] loss: 0.068\n",
      "[143,    30] loss: 0.070\n",
      "[143,    40] loss: 0.068\n",
      "[144,    10] loss: 0.068\n",
      "[144,    20] loss: 0.071\n",
      "[144,    30] loss: 0.066\n",
      "[144,    40] loss: 0.068\n",
      "[145,    10] loss: 0.069\n",
      "[145,    20] loss: 0.065\n",
      "[145,    30] loss: 0.069\n",
      "[145,    40] loss: 0.069\n",
      "[146,    10] loss: 0.059\n",
      "[146,    20] loss: 0.074\n",
      "[146,    30] loss: 0.074\n",
      "[146,    40] loss: 0.074\n",
      "[147,    10] loss: 0.066\n",
      "[147,    20] loss: 0.066\n",
      "[147,    30] loss: 0.070\n",
      "[147,    40] loss: 0.074\n",
      "[148,    10] loss: 0.069\n",
      "[148,    20] loss: 0.070\n",
      "[148,    30] loss: 0.069\n",
      "[148,    40] loss: 0.074\n",
      "[149,    10] loss: 0.062\n",
      "[149,    20] loss: 0.066\n",
      "[149,    30] loss: 0.072\n",
      "[149,    40] loss: 0.071\n",
      "[150,    10] loss: 0.074\n",
      "[150,    20] loss: 0.072\n",
      "[150,    30] loss: 0.070\n",
      "[150,    40] loss: 0.077\n",
      "[151,    10] loss: 0.066\n",
      "[151,    20] loss: 0.069\n",
      "[151,    30] loss: 0.070\n",
      "[151,    40] loss: 0.072\n",
      "[152,    10] loss: 0.065\n",
      "[152,    20] loss: 0.069\n",
      "[152,    30] loss: 0.071\n",
      "[152,    40] loss: 0.065\n",
      "[153,    10] loss: 0.067\n",
      "[153,    20] loss: 0.064\n",
      "[153,    30] loss: 0.064\n",
      "[153,    40] loss: 0.074\n",
      "[154,    10] loss: 0.059\n",
      "[154,    20] loss: 0.059\n",
      "[154,    30] loss: 0.061\n",
      "[154,    40] loss: 0.067\n",
      "[155,    10] loss: 0.063\n",
      "[155,    20] loss: 0.063\n",
      "[155,    30] loss: 0.067\n",
      "[155,    40] loss: 0.066\n",
      "[156,    10] loss: 0.062\n",
      "[156,    20] loss: 0.064\n",
      "[156,    30] loss: 0.063\n",
      "[156,    40] loss: 0.067\n",
      "[157,    10] loss: 0.061\n",
      "[157,    20] loss: 0.068\n",
      "[157,    30] loss: 0.065\n",
      "[157,    40] loss: 0.067\n",
      "[158,    10] loss: 0.063\n",
      "[158,    20] loss: 0.067\n",
      "[158,    30] loss: 0.068\n",
      "[158,    40] loss: 0.067\n",
      "[159,    10] loss: 0.070\n",
      "[159,    20] loss: 0.072\n",
      "[159,    30] loss: 0.066\n",
      "[159,    40] loss: 0.071\n",
      "[160,    10] loss: 0.069\n",
      "[160,    20] loss: 0.060\n",
      "[160,    30] loss: 0.072\n",
      "[160,    40] loss: 0.069\n",
      "[161,    10] loss: 0.064\n",
      "[161,    20] loss: 0.055\n",
      "[161,    30] loss: 0.066\n",
      "[161,    40] loss: 0.066\n",
      "[162,    10] loss: 0.063\n",
      "[162,    20] loss: 0.058\n",
      "[162,    30] loss: 0.066\n",
      "[162,    40] loss: 0.066\n",
      "[163,    10] loss: 0.059\n",
      "[163,    20] loss: 0.061\n",
      "[163,    30] loss: 0.059\n",
      "[163,    40] loss: 0.063\n",
      "[164,    10] loss: 0.065\n",
      "[164,    20] loss: 0.064\n",
      "[164,    30] loss: 0.069\n",
      "[164,    40] loss: 0.068\n",
      "[165,    10] loss: 0.060\n",
      "[165,    20] loss: 0.069\n",
      "[165,    30] loss: 0.066\n",
      "[165,    40] loss: 0.067\n",
      "[166,    10] loss: 0.062\n",
      "[166,    20] loss: 0.063\n",
      "[166,    30] loss: 0.060\n",
      "[166,    40] loss: 0.063\n",
      "[167,    10] loss: 0.065\n",
      "[167,    20] loss: 0.064\n",
      "[167,    30] loss: 0.064\n",
      "[167,    40] loss: 0.061\n",
      "[168,    10] loss: 0.057\n",
      "[168,    20] loss: 0.064\n",
      "[168,    30] loss: 0.067\n",
      "[168,    40] loss: 0.068\n",
      "[169,    10] loss: 0.063\n",
      "[169,    20] loss: 0.061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169,    30] loss: 0.060\n",
      "[169,    40] loss: 0.063\n",
      "[170,    10] loss: 0.063\n",
      "[170,    20] loss: 0.060\n",
      "[170,    30] loss: 0.067\n",
      "[170,    40] loss: 0.071\n",
      "[171,    10] loss: 0.065\n",
      "[171,    20] loss: 0.058\n",
      "[171,    30] loss: 0.073\n",
      "[171,    40] loss: 0.069\n",
      "[172,    10] loss: 0.069\n",
      "[172,    20] loss: 0.064\n",
      "[172,    30] loss: 0.073\n",
      "[172,    40] loss: 0.063\n",
      "[173,    10] loss: 0.062\n",
      "[173,    20] loss: 0.062\n",
      "[173,    30] loss: 0.069\n",
      "[173,    40] loss: 0.068\n",
      "[174,    10] loss: 0.059\n",
      "[174,    20] loss: 0.060\n",
      "[174,    30] loss: 0.065\n",
      "[174,    40] loss: 0.063\n",
      "[175,    10] loss: 0.060\n",
      "[175,    20] loss: 0.067\n",
      "[175,    30] loss: 0.065\n",
      "[175,    40] loss: 0.059\n",
      "[176,    10] loss: 0.062\n",
      "[176,    20] loss: 0.063\n",
      "[176,    30] loss: 0.063\n",
      "[176,    40] loss: 0.069\n",
      "[177,    10] loss: 0.057\n",
      "[177,    20] loss: 0.061\n",
      "[177,    30] loss: 0.058\n",
      "[177,    40] loss: 0.065\n",
      "[178,    10] loss: 0.062\n",
      "[178,    20] loss: 0.065\n",
      "[178,    30] loss: 0.066\n",
      "[178,    40] loss: 0.070\n",
      "[179,    10] loss: 0.058\n",
      "[179,    20] loss: 0.058\n",
      "[179,    30] loss: 0.053\n",
      "[179,    40] loss: 0.059\n",
      "[180,    10] loss: 0.065\n",
      "[180,    20] loss: 0.059\n",
      "[180,    30] loss: 0.062\n",
      "[180,    40] loss: 0.056\n",
      "[181,    10] loss: 0.062\n",
      "[181,    20] loss: 0.061\n",
      "[181,    30] loss: 0.066\n",
      "[181,    40] loss: 0.065\n",
      "[182,    10] loss: 0.057\n",
      "[182,    20] loss: 0.059\n",
      "[182,    30] loss: 0.069\n",
      "[182,    40] loss: 0.066\n",
      "[183,    10] loss: 0.063\n",
      "[183,    20] loss: 0.057\n",
      "[183,    30] loss: 0.058\n",
      "[183,    40] loss: 0.059\n",
      "[184,    10] loss: 0.057\n",
      "[184,    20] loss: 0.068\n",
      "[184,    30] loss: 0.063\n",
      "[184,    40] loss: 0.062\n",
      "[185,    10] loss: 0.055\n",
      "[185,    20] loss: 0.055\n",
      "[185,    30] loss: 0.063\n",
      "[185,    40] loss: 0.063\n",
      "[186,    10] loss: 0.065\n",
      "[186,    20] loss: 0.064\n",
      "[186,    30] loss: 0.062\n",
      "[186,    40] loss: 0.056\n",
      "[187,    10] loss: 0.060\n",
      "[187,    20] loss: 0.065\n",
      "[187,    30] loss: 0.065\n",
      "[187,    40] loss: 0.066\n",
      "[188,    10] loss: 0.055\n",
      "[188,    20] loss: 0.061\n",
      "[188,    30] loss: 0.060\n",
      "[188,    40] loss: 0.057\n",
      "[189,    10] loss: 0.058\n",
      "[189,    20] loss: 0.055\n",
      "[189,    30] loss: 0.057\n",
      "[189,    40] loss: 0.061\n",
      "[190,    10] loss: 0.057\n",
      "[190,    20] loss: 0.056\n",
      "[190,    30] loss: 0.060\n",
      "[190,    40] loss: 0.059\n",
      "[191,    10] loss: 0.055\n",
      "[191,    20] loss: 0.059\n",
      "[191,    30] loss: 0.051\n",
      "[191,    40] loss: 0.057\n",
      "[192,    10] loss: 0.057\n",
      "[192,    20] loss: 0.055\n",
      "[192,    30] loss: 0.058\n",
      "[192,    40] loss: 0.052\n",
      "[193,    10] loss: 0.057\n",
      "[193,    20] loss: 0.059\n",
      "[193,    30] loss: 0.064\n",
      "[193,    40] loss: 0.058\n",
      "[194,    10] loss: 0.059\n",
      "[194,    20] loss: 0.054\n",
      "[194,    30] loss: 0.059\n",
      "[194,    40] loss: 0.064\n",
      "[195,    10] loss: 0.055\n",
      "[195,    20] loss: 0.056\n",
      "[195,    30] loss: 0.058\n",
      "[195,    40] loss: 0.070\n",
      "[196,    10] loss: 0.061\n",
      "[196,    20] loss: 0.065\n",
      "[196,    30] loss: 0.059\n",
      "[196,    40] loss: 0.060\n",
      "[197,    10] loss: 0.057\n",
      "[197,    20] loss: 0.062\n",
      "[197,    30] loss: 0.055\n",
      "[197,    40] loss: 0.056\n",
      "[198,    10] loss: 0.055\n",
      "[198,    20] loss: 0.055\n",
      "[198,    30] loss: 0.059\n",
      "[198,    40] loss: 0.061\n",
      "[199,    10] loss: 0.056\n",
      "[199,    20] loss: 0.055\n",
      "[199,    30] loss: 0.054\n",
      "[199,    40] loss: 0.061\n",
      "[200,    10] loss: 0.055\n",
      "[200,    20] loss: 0.061\n",
      "[200,    30] loss: 0.053\n",
      "[200,    40] loss: 0.062\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(200):   # 데이터셋을 수차례 반복합니다.\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]의 목록인 data로부터 입력을 받은 후;\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 통계를 출력합니다.\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SYFO6TofWz-0"
   },
   "outputs": [],
   "source": [
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi8HjximWz5-",
    "outputId": "688f3e8e-f55b-4d0d-b51c-d29a5e2c8c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane  frog  frog   car  frog   cat   car plane truck   dog horse truck  ship   dog horse  ship  frog horse plane  deer truck   dog  bird  deer plane truck  frog  frog   dog  deer   dog truck  bird  deer   car truck   dog  deer  frog   dog  frog plane truck   cat truck horse  frog truck  ship plane   cat  ship  ship horse horse  deer  frog horse   cat  frog   cat\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "# 이미지를 출력합니다.\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eAQ14i67Xzdk"
   },
   "outputs": [],
   "source": [
    "# net = Net()\n",
    "# net.to(device)\n",
    "# net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xW5s_VvOX2Kr"
   },
   "outputs": [],
   "source": [
    "net.train()\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EUVmr_-X2IL",
    "outputId": "07dd4599-2c71-46e0-f132-e1f09e678af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship   car plane  deer  frog   car   cat   cat   car   dog truck  deer horse truck  ship   dog horse  ship  frog horse plane   cat truck  deer  bird  deer plane truck  frog  frog   dog  bird   cat truck  ship horse   car truck   dog  deer  frog   dog  frog plane truck   cat truck horse  frog truck  ship   cat   cat  ship  ship horse   cat  bird   cat horse   cat  frog   cat  frog  bird   car  bird   cat horse  bird  frog  ship  ship plane  bird plane   cat   cat  ship  ship   car   car horse  bird horse  bird horse  ship truck plane  frog  ship  frog  deer  frog  frog plane plane   dog   dog   dog   dog   cat   car   car   cat  frog  ship horse horse plane  frog  bird   car   cat plane  deer  frog   cat  ship   cat   car  bird  ship plane  ship   dog   cat  bird  deer   car  ship truck   car  bird truck horse  bird  ship  frog   dog  frog   cat  ship truck  frog   dog   dog  bird  ship truck  frog plane plane   dog  frog truck   cat  deer  bird   car  deer  frog  ship horse  ship  deer   dog  ship truck truck truck  ship truck truck   cat horse   cat plane plane   dog plane  bird   cat  ship  frog   dog horse plane   dog  ship horse   car   dog  frog  ship  ship horse  ship   dog   car  ship horse   car   cat plane   dog horse truck horse   car   dog truck  ship   dog horse truck  ship  bird horse  deer truck horse   cat truck  deer  deer   dog  frog   cat   car   dog  ship  ship plane  deer plane   dog   cat   car   car  ship truck plane  bird   car  ship  deer  bird   dog   cat truck truck  deer plane  frog plane  ship truck  ship   car   dog   dog  ship plane  bird  deer horse plane  bird  frog  frog   cat  ship horse plane  bird horse horse truck  ship  frog   car plane truck   car plane horse truck   car  bird  frog   car   cat  deer  frog plane plane  frog  frog  frog   cat  bird  frog   car truck  bird   car  deer   car  frog plane  bird  deer plane horse horse   dog   dog   cat   dog  bird  frog horse   car horse   dog  deer  frog   car truck  deer  frog  frog truck   cat  ship plane horse   cat  frog  bird  deer  ship   dog  deer  frog  ship truck truck   car  ship  bird  bird  deer horse  bird  ship plane truck   dog  ship  ship truck  deer plane   cat plane   car  bird horse truck  deer  bird horse truck horse  ship  frog  frog truck plane   car   dog  ship horse  bird   cat   dog   car plane  frog  bird truck  frog  bird   cat plane   cat truck   car horse  ship  ship  deer plane   car  ship  bird horse truck  deer  frog   car truck   cat horse horse horse  deer   dog  ship plane  frog truck   cat   cat truck  frog   cat   dog   cat   cat truck horse  bird   dog   cat   car   car horse truck truck   dog  deer   dog plane  bird plane  frog truck horse  frog truck  bird  deer  deer  bird  bird   dog  frog   car  deer  deer  deer horse   dog horse  ship  deer horse  ship truck  deer horse  bird plane   dog  deer  ship  frog  ship   dog   dog plane truck truck  deer  bird   car plane  ship   car   car  ship plane   dog  bird plane  deer  frog   dog  deer truck  deer horse truck truck  deer   dog  frog  frog   car   dog   cat  ship truck   cat  ship   dog horse plane horse plane   dog horse plane  deer  frog truck truck truck   dog  frog  frog  frog  bird truck truck   car horse  frog horse   dog truck   car  frog  bird   dog   dog   cat  ship   dog truck plane  frog  deer   cat  bird plane horse  frog  deer  frog   cat truck   cat truck  bird  bird horse   car   dog  frog  frog  ship  ship horse   dog  deer plane  ship  deer plane truck   dog  deer  ship truck  frog truck  bird  frog   car plane horse  bird  frog   cat  ship   dog plane  bird   car  frog  deer   dog   cat truck  frog truck  ship  ship   dog truck  frog  frog horse   car horse horse   car  bird horse truck   car  deer  deer horse  bird   dog  frog  ship horse  frog  ship   cat  ship   dog   dog   cat   dog horse truck   car   cat   dog  deer   dog   cat   car   dog  frog truck  bird   car  frog  deer   car truck  deer horse  bird   cat plane truck plane   car   cat  frog   dog  bird   cat  bird  ship  deer truck plane   dog truck  frog  deer plane truck   cat truck  frog  frog  deer  deer  bird  bird horse  ship  frog  ship  bird horse   dog horse  bird  deer  ship horse  deer  bird truck  ship  ship  bird plane  ship horse  deer   dog   cat  ship  deer  ship  deer  ship  ship   car  ship plane truck  bird  frog   dog  deer plane horse truck  bird  frog   car  deer   car   dog   dog horse plane horse  frog horse  deer  frog  bird   cat truck  deer truck   car  bird  bird  frog  ship  bird   car   cat   dog  frog plane   car  bird plane truck   dog  deer horse   car  frog  deer  bird  deer   cat  frog plane   dog truck   car horse  frog horse plane   cat truck  deer  ship  deer plane  frog   cat horse horse  deer  deer horse  frog horse   car plane horse  deer  deer  ship  deer   dog horse  bird   dog horse  bird plane  ship truck   cat  ship   dog truck  bird  bird  ship horse   cat horse  frog   dog   cat   car   cat  bird  bird   dog  deer   car   dog truck  bird horse  ship horse  bird   car  bird  bird plane  bird  deer   dog truck  ship   car plane horse horse  ship horse  ship  deer  frog  frog   cat plane   car   dog horse plane   car   cat   car  deer  bird   cat  ship  deer   dog   cat horse  ship  frog plane plane truck plane plane  ship plane  frog  deer  frog horse   cat truck   car   cat horse   dog   dog  frog  frog  frog   dog  ship horse   car  frog  ship  ship   dog   cat   dog  deer plane   car  deer  ship  ship plane  frog truck horse  frog   dog   cat  ship  frog  bird plane  deer  bird   cat   dog horse  bird   cat   dog   car  ship truck  bird horse  frog plane horse plane   car  deer  ship  bird truck  frog plane  deer horse truck  frog horse  ship truck   car   car  frog  frog  frog truck truck   car truck truck  deer   dog   car  bird plane  frog  ship  ship truck  bird truck   cat  deer horse  ship   cat   car  bird plane   car   dog  ship horse  ship   cat  ship  ship   cat  ship   dog plane  ship  deer plane   car   car  ship truck  frog plane  ship  frog   car   cat  deer   car  frog plane   dog   car   car plane plane\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fKdJHWbX2DR",
    "outputId": "038c26f6-4ab3-4954-c104-504a9fdd2d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSiYXtBCYEJx",
    "outputId": "26710488-3eac-49fe-defb-67c03011007c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class plane is: 81.5 %\n",
      "Accuracy for class car   is: 91.1 %\n",
      "Accuracy for class bird  is: 70.1 %\n",
      "Accuracy for class cat   is: 60.2 %\n",
      "Accuracy for class deer  is: 77.3 %\n",
      "Accuracy for class dog   is: 70.9 %\n",
      "Accuracy for class frog  is: 86.6 %\n",
      "Accuracy for class horse is: 84.7 %\n",
      "Accuracy for class ship  is: 87.4 %\n",
      "Accuracy for class truck is: 86.2 %\n"
     ]
    }
   ],
   "source": [
    "# 각 분류(class)에 대한 예측값 계산을 위해 준비\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "union",
   "language": "python",
   "name": "union"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
